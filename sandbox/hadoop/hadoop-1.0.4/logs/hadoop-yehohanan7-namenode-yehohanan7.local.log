2012-10-14 00:07:45,379 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 00:07:45,495 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 00:07:45,505 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 00:07:45,506 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 00:07:45,506 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 00:07:45,602 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 00:07:45,611 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 00:07:45,612 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 00:07:45,630 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 00:07:45,630 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 00:07:45,630 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 00:07:45,630 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 00:07:45,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 00:07:45,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 00:07:45,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 00:07:45,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 00:07:45,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 00:07:45,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 00:07:45,805 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 00:07:45,820 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 3
2012-10-14 00:07:45,826 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 00:07:45,826 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 298 loaded in 0 seconds.
2012-10-14 00:07:45,826 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 00:07:45,828 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 298 saved in 0 seconds.
2012-10-14 00:07:45,865 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 298 saved in 0 seconds.
2012-10-14 00:07:45,872 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 00:07:45,872 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 229 msecs
2012-10-14 00:07:45,880 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The ratio of reported blocks 0.0000 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
2012-10-14 00:07:45,885 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 00:07:45,889 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 00:07:45,910 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 00:07:45,912 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2012-10-14 00:07:45,912 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2012-10-14 00:07:45,914 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2012-10-14 00:07:45,967 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 00:07:46,014 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 00:07:46,021 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 00:07:46,027 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 00:07:46,029 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 00:07:46,029 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 00:07:46,029 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 00:07:46,362 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 00:07:46,362 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 00:07:46,362 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 00:07:46,363 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2012-10-14 00:07:46,364 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2012-10-14 00:07:46,365 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2012-10-14 00:07:46,365 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2012-10-14 00:07:46,365 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2012-10-14 00:07:46,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2012-10-14 00:07:46,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2012-10-14 00:07:46,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2012-10-14 00:07:46,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2012-10-14 00:07:46,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2012-10-14 00:07:46,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2012-10-14 00:07:47,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-1815811049-192.168.2.16-50010-1350153034710
2012-10-14 00:07:47,971 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2012-10-14 00:07:47,985 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 29 seconds.
2012-10-14 00:07:47,985 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameSystem.processReport: from 127.0.0.1:50010, blocks: 1, processing time: 2 msecs
2012-10-14 00:08:08,004 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 9 seconds.
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 10 msec
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs.
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2012-10-14 00:08:18,024 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 00:08:18,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 00:08:18,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 00:08:18,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 00:08:18,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 00:09:01,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 3 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2012-10-14 00:09:01,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /test/httpspect.txt. blk_7196268681443810795_1002
2012-10-14 00:09:01,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_7196268681443810795_1002 size 202837
2012-10-14 00:09:01,848 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /test/httpspect.txt from client DFSClient_-1117190456
2012-10-14 00:09:01,849 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /test/httpspect.txt is closed by DFSClient_-1117190456
2012-10-14 00:10:55,609 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 7 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 2 
2012-10-14 00:12:49,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2012-10-14 00:12:49,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 7 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3 
2012-10-14 00:12:49,467 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 127.0.0.1
2012-10-14 00:12:49,467 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 2 
2012-10-14 00:15:16,438 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 00:15:16,443 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 00:15:16,461 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 00:15:16,461 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 00:15:16,476 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2338)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:831)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 00:15:16,477 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 00:15:19,377 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 00:15:19,378 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 00:15:19,394 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 00:15:19,394 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 00:15:19,408 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2338)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:831)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 00:15:19,409 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:16:34,590 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameSystem.processReport: from 127.0.0.1:50010, blocks: 2, processing time: 0 msecs
2012-10-14 04:17:43,009 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:43,013 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:43,031 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:43,032 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:43,050 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2338)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:831)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:43,050 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:52,189 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:52,190 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:52,204 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:52,204 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:52,219 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2338)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:831)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:52,219 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:55,364 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:55,365 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:55,383 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:55,384 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:55,402 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:898)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:55,403 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:55,443 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:898)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:55,444 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:17:55,493 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:898)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:17:55,494 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:18:56,886 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2012-10-14 04:18:56,887 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 1 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2012-10-14 04:18:56,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 127.0.0.1
2012-10-14 04:18:56,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 1 
2012-10-14 04:18:57,000 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:19:01,849 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:19:01,971 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:19:01,979 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:19:01,980 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:19:01,980 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:19:02,075 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:19:02,083 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:19:02,083 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:19:02,104 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:19:02,104 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:19:02,104 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:19:02,104 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:19:02,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:19:02,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:19:02,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:19:02,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:19:02,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:19:02,263 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:19:02,280 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:19:02,294 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 8
2012-10-14 04:19:02,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:19:02,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 734 loaded in 0 seconds.
2012-10-14 04:19:02,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 04:19:02,303 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 734 saved in 0 seconds.
2012-10-14 04:19:02,340 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 734 saved in 0 seconds.
2012-10-14 04:19:02,348 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:19:02,348 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 231 msecs
2012-10-14 04:19:02,354 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The ratio of reported blocks 0.0000 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
2012-10-14 04:19:02,360 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:19:02,364 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:19:02,385 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:19:02,387 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2012-10-14 04:19:02,388 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2012-10-14 04:19:02,390 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2012-10-14 04:19:02,476 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:19:02,530 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:19:02,540 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:19:02,546 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:19:02,547 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:19:02,547 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:19:02,547 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:19:02,851 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:19:02,858 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:19:02,858 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:19:02,859 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2012-10-14 04:19:02,860 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2012-10-14 04:19:02,860 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2012-10-14 04:19:02,860 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2012-10-14 04:19:02,867 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2012-10-14 04:19:02,868 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2012-10-14 04:19:02,868 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2012-10-14 04:19:02,869 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2012-10-14 04:19:02,869 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2012-10-14 04:19:02,869 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2012-10-14 04:19:02,869 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2012-10-14 04:19:04,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-1815811049-192.168.2.16-50010-1350153034710
2012-10-14 04:19:04,301 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2012-10-14 04:19:04,309 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 30 seconds.
2012-10-14 04:19:04,309 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameSystem.processReport: from 127.0.0.1:50010, blocks: 2, processing time: 1 msecs
2012-10-14 04:19:24,329 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 9 seconds.
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 2
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 19 msec
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs.
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2012-10-14 04:19:34,356 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:19:35,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:19:35,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:19:35,371 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:19:35,371 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:20:46,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 3 Total time for transactions(ms): 1Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2012-10-14 04:20:46,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /tikvah/README.txt. blk_5808402412817480128_1003
2012-10-14 04:20:46,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_5808402412817480128_1003 size 50
2012-10-14 04:20:46,217 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /tikvah/README.txt from client DFSClient_343741130
2012-10-14 04:20:46,218 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /tikvah/README.txt is closed by DFSClient_343741130
2012-10-14 04:21:11,387 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:11,388 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:11,403 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:11,404 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:11,421 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2338)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:831)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:11,422 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:13,555 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:13,555 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:13,570 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:13,570 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:13,584 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2338)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:831)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:13,585 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:14,926 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:14,927 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:14,944 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5193)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:14,945 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:14,963 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:898)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:14,964 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:15,019 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:898)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:15,019 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:15,038 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:898)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:15,039 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:21:15,063 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5210)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:5178)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:926)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:898)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:21:15,064 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2012-10-14 04:23:02,984 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:23:06,410 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:23:06,524 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:23:06,533 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:23:06,534 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:23:06,534 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:23:06,633 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:23:06,643 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:23:06,644 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:23:06,664 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:23:06,664 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:23:06,664 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:23:06,664 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:23:06,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:23:06,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:23:06,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:23:06,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:23:06,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:23:06,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:23:06,846 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:23:06,861 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2012-10-14 04:23:06,865 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:23:06,865 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 loaded in 0 seconds.
2012-10-14 04:23:06,866 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 04:23:06,867 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:23:06,905 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:23:06,911 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:23:06,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 234 msecs
2012-10-14 04:23:06,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2012-10-14 04:23:06,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:23:06,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:23:06,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:23:06,920 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 7 msec
2012-10-14 04:23:06,920 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2012-10-14 04:23:06,921 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2012-10-14 04:23:06,921 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:23:06,927 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:23:06,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:23:06,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:23:06,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:23:06,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:23:06,931 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:23:06,955 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:23:06,956 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2012-10-14 04:23:06,957 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2012-10-14 04:23:06,959 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2012-10-14 04:23:07,038 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:23:07,097 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:23:07,104 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:23:07,108 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:23:07,111 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:23:07,111 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:23:07,111 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:23:07,433 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:23:07,433 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:23:07,434 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:23:07,434 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2012-10-14 04:23:07,435 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2012-10-14 04:23:07,436 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2012-10-14 04:23:07,436 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2012-10-14 04:23:07,436 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2012-10-14 04:23:07,436 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2012-10-14 04:23:07,436 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2012-10-14 04:23:07,437 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2012-10-14 04:23:07,437 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2012-10-14 04:23:07,437 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2012-10-14 04:23:07,437 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2012-10-14 04:23:43,483 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
2012-10-14 04:23:43,484 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call addBlock(/tikvah/README.txt, DFSClient_-1302225982, null) from 127.0.0.1:51106: error: java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:25:20,997 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:25:25,819 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:25:25,944 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:25:25,954 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:25:25,955 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:25:25,955 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:25:26,056 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:25:26,066 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:25:26,067 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:25:26,085 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:25:26,085 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:25:26,085 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:25:26,085 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:25:26,106 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:25:26,106 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:25:26,107 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:25:26,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:25:26,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:25:26,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:25:26,261 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:25:26,276 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)
2012-10-14 04:25:26,277 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)

2012-10-14 04:25:26,278 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:25:37,861 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:25:37,982 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:25:37,990 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:25:37,991 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:25:37,991 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:25:38,089 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:25:38,099 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:25:38,100 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:25:38,121 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:25:38,122 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:25:38,122 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:25:38,122 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:25:38,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:25:38,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:25:38,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:25:38,149 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:25:38,149 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:25:38,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:25:38,316 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:25:38,331 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)
2012-10-14 04:25:38,332 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)

2012-10-14 04:25:38,332 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:26:11,184 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:26:11,297 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:26:11,306 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:26:11,307 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:26:11,307 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:26:11,406 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:26:11,415 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:26:11,416 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:26:11,435 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:26:11,435 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:26:11,435 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:26:11,436 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:26:11,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:26:11,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:26:11,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:26:11,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:26:11,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:26:11,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:26:11,608 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:26:11,625 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)
2012-10-14 04:26:11,626 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)

2012-10-14 04:26:11,626 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:26:32,383 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:26:32,498 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:26:32,507 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:26:32,508 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:26:32,508 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:26:32,609 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:26:32,619 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:26:32,621 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:26:32,643 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:26:32,643 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:26:32,643 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:26:32,643 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:26:32,670 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:26:32,670 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:26:32,670 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:26:32,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:26:32,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:26:32,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:26:32,824 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:26:32,842 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)
2012-10-14 04:26:32,843 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)

2012-10-14 04:26:32,843 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:27:39,807 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:27:39,925 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:27:39,934 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:27:39,935 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:27:39,935 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:27:40,037 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:27:40,046 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:27:40,047 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:27:40,067 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:27:40,067 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:27:40,067 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:27:40,067 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:27:40,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:27:40,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:27:40,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:27:40,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:27:40,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:27:40,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:27:40,246 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:27:40,488 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2012-10-14 04:27:40,492 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:27:40,492 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 loaded in 0 seconds.
2012-10-14 04:27:40,493 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 04:27:40,494 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:27:40,842 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:27:40,850 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:27:40,850 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 770 msecs
2012-10-14 04:27:40,858 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2012-10-14 04:27:40,858 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:27:40,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:27:40,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:27:40,859 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 8 msec
2012-10-14 04:27:40,859 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2012-10-14 04:27:40,859 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2012-10-14 04:27:40,859 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:27:40,865 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:27:40,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:27:40,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:27:40,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:27:40,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:27:40,869 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:27:40,893 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:27:40,895 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2012-10-14 04:27:40,896 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2012-10-14 04:27:40,930 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2012-10-14 04:27:41,009 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:27:41,065 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:27:41,074 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:27:41,080 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:27:41,082 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:27:41,082 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:27:41,082 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:27:41,429 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:27:41,429 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:27:41,429 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:27:41,429 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2012-10-14 04:27:41,430 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2012-10-14 04:27:41,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2012-10-14 04:28:08,922 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
2012-10-14 04:28:08,923 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call addBlock(/tikvah/README.txt, DFSClient_-2019496460, null) from 127.0.0.1:51485: error: java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:29:36,098 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:30:49,775 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:30:49,898 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:30:49,909 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:30:49,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:30:49,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:30:50,008 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:30:50,017 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:30:50,018 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:30:50,037 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:30:50,038 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:30:50,038 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:30:50,038 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:30:50,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:30:50,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:30:50,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2012-10-14 04:30:50,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:30:50,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:30:50,203 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:30:50,220 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:30:50,238 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)
2012-10-14 04:30:50,238 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)

2012-10-14 04:30:50,239 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:31:30,164 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:31:30,292 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:31:30,300 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:31:30,301 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:31:30,301 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:31:30,398 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:31:30,407 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:31:30,408 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:31:30,429 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:31:30,430 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:31:30,430 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:31:30,430 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:31:30,451 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:31:30,451 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:31:30,451 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2012-10-14 04:31:30,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:31:30,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:31:30,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:31:30,606 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:31:30,619 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2012-10-14 04:31:30,623 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:31:30,623 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 loaded in 0 seconds.
2012-10-14 04:31:30,623 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 04:31:30,624 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:31:30,662 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:31:30,669 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:31:30,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 226 msecs
2012-10-14 04:31:30,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2012-10-14 04:31:30,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:31:30,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:31:30,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:31:30,678 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 8 msec
2012-10-14 04:31:30,678 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2012-10-14 04:31:30,678 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2012-10-14 04:31:30,678 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:31:30,683 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:31:30,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:31:30,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:31:30,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:31:30,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:31:30,688 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:31:30,713 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:31:30,715 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9000 registered.
2012-10-14 04:31:30,715 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9000 registered.
2012-10-14 04:31:30,718 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:9000
2012-10-14 04:31:30,768 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:31:30,818 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:31:30,826 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:31:30,833 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:31:30,835 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:31:30,835 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:31:30,835 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:31:31,141 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:31:31,141 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:31:31,141 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:31:31,142 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2012-10-14 04:31:31,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000: starting
2012-10-14 04:31:31,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000: starting
2012-10-14 04:31:31,144 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000: starting
2012-10-14 04:31:31,144 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000: starting
2012-10-14 04:31:31,144 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000: starting
2012-10-14 04:31:31,144 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000: starting
2012-10-14 04:31:31,144 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000: starting
2012-10-14 04:31:31,145 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000: starting
2012-10-14 04:31:31,145 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000: starting
2012-10-14 04:31:31,145 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000: starting
2012-10-14 04:31:35,009 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:31:35,010 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51790: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:31:45,029 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:31:45,029 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51796: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:31:55,043 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:31:55,043 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51800: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:32:05,058 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:32:05,058 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51800: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:32:15,071 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:32:15,071 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51801: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:32:25,088 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:32:25,089 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51802: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:32:35,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 34 Total time for transactions(ms): 1Number of transactions batched in Syncs: 0 Number of syncs: 22 SyncTimes(ms): 9 
2012-10-14 04:32:35,099 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:32:35,099 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51802: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:32:45,114 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:32:45,114 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51805: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:32:55,127 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:32:55,127 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51806: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:33:05,143 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:33:05,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51806: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:33:15,159 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:33:15,160 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51807: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:33:25,175 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:33:25,175 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51808: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:33:35,185 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 58 Total time for transactions(ms): 2Number of transactions batched in Syncs: 0 Number of syncs: 40 SyncTimes(ms): 14 
2012-10-14 04:33:35,189 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:33:35,189 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51808: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:33:45,203 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:33:45,203 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51814: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:33:55,218 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:33:55,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51829: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:34:05,238 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:34:05,238 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51829: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:34:15,254 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:34:15,254 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51847: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:34:25,270 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:34:25,270 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51851: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:34:35,281 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 82 Total time for transactions(ms): 2Number of transactions batched in Syncs: 0 Number of syncs: 58 SyncTimes(ms): 23 
2012-10-14 04:34:35,284 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:34:35,284 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51851: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:34:45,297 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:34:45,297 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51862: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:34:55,311 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:34:55,311 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1994618063, null) from 127.0.0.1:51866: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:34:59,516 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:35:02,101 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:35:02,217 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:35:02,225 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:35:02,226 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:35:02,226 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:35:02,319 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:35:02,327 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:35:02,328 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:35:02,346 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:35:02,346 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:35:02,346 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:35:02,346 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:35:02,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:35:02,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:35:02,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2012-10-14 04:35:02,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:35:02,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:35:02,501 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:35:02,518 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:35:02,535 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)
2012-10-14 04:35:02,536 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:330)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)

2012-10-14 04:35:02,537 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:36:14,203 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:36:14,330 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:36:14,340 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:36:14,341 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:36:14,341 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:36:14,444 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:36:14,452 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:36:14,452 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:36:14,470 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:36:14,470 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:36:14,470 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:36:14,470 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:36:14,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:36:14,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:36:14,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2012-10-14 04:36:14,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:36:14,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:36:14,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:36:14,648 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:36:14,663 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2012-10-14 04:36:14,667 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:36:14,667 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 loaded in 0 seconds.
2012-10-14 04:36:14,667 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 04:36:14,668 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:36:14,704 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:36:14,710 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:36:14,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 226 msecs
2012-10-14 04:36:14,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2012-10-14 04:36:14,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:36:14,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:36:14,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:36:14,719 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 8 msec
2012-10-14 04:36:14,719 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2012-10-14 04:36:14,719 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2012-10-14 04:36:14,719 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:36:14,725 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:36:14,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:36:14,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:36:14,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:36:14,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:36:14,729 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:36:14,752 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:36:14,755 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9000 registered.
2012-10-14 04:36:14,755 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9000 registered.
2012-10-14 04:36:14,758 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:9000
2012-10-14 04:36:14,809 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:36:14,863 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:36:14,872 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:36:14,877 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:36:14,879 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:36:14,879 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:36:14,879 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:36:15,209 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:36:15,210 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:36:15,229 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:36:15,229 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2012-10-14 04:36:15,233 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000: starting
2012-10-14 04:36:15,233 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000: starting
2012-10-14 04:36:15,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000: starting
2012-10-14 04:36:15,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000: starting
2012-10-14 04:36:15,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000: starting
2012-10-14 04:36:15,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000: starting
2012-10-14 04:36:15,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000: starting
2012-10-14 04:36:15,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000: starting
2012-10-14 04:36:15,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000: starting
2012-10-14 04:36:15,235 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000: starting
2012-10-14 04:36:19,102 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:36:19,103 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52113: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:36:29,121 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:36:29,121 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52121: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:36:39,138 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:36:39,138 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52133: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:36:49,153 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:36:49,153 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52133: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:36:59,168 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:36:59,168 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52140: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:37:09,191 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:37:09,191 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52143: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:37:19,199 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 34 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 22 SyncTimes(ms): 9 
2012-10-14 04:37:19,202 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:37:19,202 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52143: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:37:29,216 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
2012-10-14 04:37:29,216 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call addBlock(/tmp/hadoop-yehohanan7/mapred/system/jobtracker.info, DFSClient_-1558438504, null) from 127.0.0.1:52144: error: java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tmp/hadoop-yehohanan7/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:37:30,627 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:37:33,338 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:37:33,468 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:37:33,478 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:37:33,479 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:37:33,479 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:37:33,579 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:37:33,588 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:37:33,589 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:37:33,611 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:37:33,611 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:37:33,611 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:37:33,611 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:37:33,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:37:33,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:37:33,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2012-10-14 04:37:33,635 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:37:33,635 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:37:33,785 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:37:33,802 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:37:33,818 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2012-10-14 04:37:33,822 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:37:33,823 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 loaded in 0 seconds.
2012-10-14 04:37:33,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Invalid opcode, reached end of edit log Number of transactions found 40
2012-10-14 04:37:33,832 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 1049092 edits # 40 loaded in 0 seconds.
2012-10-14 04:37:33,833 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 755 saved in 0 seconds.
2012-10-14 04:37:33,869 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 755 saved in 0 seconds.
2012-10-14 04:37:33,876 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:37:33,876 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 252 msecs
2012-10-14 04:37:33,884 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2012-10-14 04:37:33,884 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:37:33,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:37:33,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:37:33,885 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 8 msec
2012-10-14 04:37:33,885 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2012-10-14 04:37:33,885 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2012-10-14 04:37:33,885 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:37:33,893 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:37:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:37:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:37:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:37:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:37:33,897 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:37:33,918 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:37:33,921 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2012-10-14 04:37:33,921 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2012-10-14 04:37:33,924 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2012-10-14 04:37:33,964 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:37:34,010 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:37:34,018 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:37:34,025 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:37:34,027 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:37:34,027 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:37:34,027 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:37:34,360 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:37:34,360 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:37:34,360 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:37:34,360 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2012-10-14 04:37:34,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2012-10-14 04:37:34,363 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2012-10-14 04:37:34,363 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2012-10-14 04:37:34,363 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2012-10-14 04:37:34,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2012-10-14 04:37:34,363 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2012-10-14 04:37:34,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2012-10-14 04:37:34,366 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2012-10-14 04:37:34,367 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2012-10-14 04:37:34,367 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2012-10-14 04:37:55,888 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:38:07,379 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:38:07,504 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:38:07,513 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:38:07,514 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:38:07,514 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:38:07,619 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:38:07,628 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:38:07,629 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:38:07,648 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:38:07,648 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:38:07,648 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:38:07,648 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:38:07,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:38:07,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:38:07,670 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2012-10-14 04:38:07,673 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:38:07,673 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:38:07,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:38:07,823 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:38:07,838 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2012-10-14 04:38:07,841 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:38:07,842 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 loaded in 0 seconds.
2012-10-14 04:38:07,842 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 04:38:07,843 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:38:07,880 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:38:07,887 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:38:07,887 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 226 msecs
2012-10-14 04:38:07,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2012-10-14 04:38:07,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:38:07,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:38:07,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:38:07,895 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 7 msec
2012-10-14 04:38:07,895 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2012-10-14 04:38:07,896 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2012-10-14 04:38:07,896 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:38:07,902 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:38:07,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:38:07,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:38:07,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:38:07,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:38:07,906 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:38:07,928 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:38:07,931 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2012-10-14 04:38:07,931 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2012-10-14 04:38:07,933 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2012-10-14 04:38:07,985 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:38:08,039 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:38:08,049 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:38:08,054 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:38:08,057 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:38:08,057 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:38:08,057 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:38:08,373 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:38:08,373 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:38:08,373 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:38:08,373 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2012-10-14 04:38:08,374 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2012-10-14 04:38:08,385 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2012-10-14 04:38:08,385 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2012-10-14 04:38:08,385 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2012-10-14 04:38:08,385 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2012-10-14 04:38:08,385 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2012-10-14 04:38:08,386 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2012-10-14 04:38:08,386 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2012-10-14 04:38:08,386 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2012-10-14 04:38:08,386 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2012-10-14 04:38:18,326 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
2012-10-14 04:38:18,326 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call addBlock(/tikvah/README.txt, DFSClient_-1296355725, null) from 127.0.0.1:52199: error: java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:39:00,471 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 04:39:12,248 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 04:39:12,376 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 04:39:12,388 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 04:39:12,389 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 04:39:12,389 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 04:39:12,487 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 04:39:12,496 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 04:39:12,497 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 04:39:12,516 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 04:39:12,516 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 04:39:12,517 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 04:39:12,517 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 04:39:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 04:39:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 04:39:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 04:39:12,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 04:39:12,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 04:39:12,690 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 04:39:12,706 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 04:39:12,723 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2012-10-14 04:39:12,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2012-10-14 04:39:12,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 loaded in 0 seconds.
2012-10-14 04:39:12,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-yehohanan7/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2012-10-14 04:39:12,729 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:39:12,769 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 116 saved in 0 seconds.
2012-10-14 04:39:12,776 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2012-10-14 04:39:12,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 246 msecs
2012-10-14 04:39:12,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2012-10-14 04:39:12,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2012-10-14 04:39:12,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2012-10-14 04:39:12,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2012-10-14 04:39:12,784 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 7 msec
2012-10-14 04:39:12,785 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2012-10-14 04:39:12,785 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2012-10-14 04:39:12,785 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2012-10-14 04:39:12,790 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2012-10-14 04:39:12,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2012-10-14 04:39:12,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2012-10-14 04:39:12,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2012-10-14 04:39:12,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2012-10-14 04:39:12,794 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2012-10-14 04:39:12,819 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2012-10-14 04:39:12,821 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2012-10-14 04:39:12,821 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2012-10-14 04:39:12,824 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2012-10-14 04:39:12,870 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-10-14 04:39:12,918 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2012-10-14 04:39:12,925 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2012-10-14 04:39:12,931 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2012-10-14 04:39:12,934 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2012-10-14 04:39:12,934 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2012-10-14 04:39:12,934 INFO org.mortbay.log: jetty-6.1.26
2012-10-14 04:39:13,269 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2012-10-14 04:39:13,269 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2012-10-14 04:39:13,271 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2012-10-14 04:39:13,273 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2012-10-14 04:39:13,276 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2012-10-14 04:39:13,276 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2012-10-14 04:39:13,277 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2012-10-14 04:39:13,277 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2012-10-14 04:39:13,278 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2012-10-14 04:39:13,278 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2012-10-14 04:39:13,279 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2012-10-14 04:39:13,279 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2012-10-14 04:39:13,279 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2012-10-14 04:39:13,279 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2012-10-14 04:39:21,251 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
2012-10-14 04:39:21,252 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call addBlock(/tikvah/README.txt, DFSClient_-1228066967, null) from 127.0.0.1:52226: error: java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /tikvah/README.txt could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1558)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:696)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 04:41:18,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 6 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 1 
2012-10-14 04:44:15,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2012-10-14 04:44:15,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 6 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 1 
2012-10-14 04:44:15,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 127.0.0.1
2012-10-14 04:44:15,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 1 
2012-10-14 05:06:12,640 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:06:12,646 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:06:12,646 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call toString() from 127.0.0.1:52508: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:06:18,805 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:06:18,806 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:06:18,806 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call toString() from 127.0.0.1:52508: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:06:25,883 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:06:25,883 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:06:25,883 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call toString() from 127.0.0.1:52508: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:06:56,098 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:06:56,098 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:06:56,098 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call toString() from 127.0.0.1:52509: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:36,664 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:36,665 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:36,665 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:41,032 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:41,033 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:41,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:41,890 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:41,890 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:41,890 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,281 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,282 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:42,282 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,283 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,283 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:42,283 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,858 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,858 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:42,858 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,859 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:42,859 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:42,859 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:52,344 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:52,344 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:52,344 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:53,304 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:53,305 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:53,305 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:58,353 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:07:58,354 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:07:58,354 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:00,232 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:00,233 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:08:00,233 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:00,234 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:00,234 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:08:00,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:01,729 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:01,730 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:08:01,730 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:11,533 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:11,533 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:08:11,533 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:13,109 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:13,110 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:08:13,110 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call toString() from 127.0.0.1:52510: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:43,079 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:43,080 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:08:43,080 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call toString() from 127.0.0.1:52524: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:45,721 ERROR org.apache.hadoop.ipc.Server: Unexpected throwable object 
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:08:45,721 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:yehohanan7 cause:java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
2012-10-14 05:08:45,721 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call toString() from 127.0.0.1:52524: error: java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
java.io.IOException: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.protocol.ClientProtocol.toString()
	at java.lang.Class.getMethod(Class.java:1605)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
2012-10-14 05:09:37,732 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
2012-10-14 23:39:40,052 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = yehohanan7.local/192.168.2.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.4
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0 -r 1393290; compiled by 'hortonfo' on Wed Oct  3 05:13:58 UTC 2012
************************************************************/
2012-10-14 23:39:40,711 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2012-10-14 23:39:40,759 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2012-10-14 23:39:40,759 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2012-10-14 23:39:40,759 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2012-10-14 23:39:41,028 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2012-10-14 23:39:41,110 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2012-10-14 23:39:41,111 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2012-10-14 23:39:41,205 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2012-10-14 23:39:41,205 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.83375 MB
2012-10-14 23:39:41,205 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2012-10-14 23:39:41,205 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2012-10-14 23:39:41,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=yehohanan7
2012-10-14 23:39:41,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2012-10-14 23:39:41,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2012-10-14 23:39:41,314 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2012-10-14 23:39:41,314 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2012-10-14 23:39:41,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2012-10-14 23:39:41,886 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2012-10-14 23:39:41,889 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /private/tmp/hadoop-yehohanan7/dfs/name does not exist.
2012-10-14 23:39:41,891 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /private/tmp/hadoop-yehohanan7/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:303)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)
2012-10-14 23:39:41,892 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /private/tmp/hadoop-yehohanan7/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:303)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:100)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:388)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:362)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:496)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)

2012-10-14 23:39:41,892 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at yehohanan7.local/192.168.2.16
************************************************************/
